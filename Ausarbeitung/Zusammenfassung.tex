\section{Zusammenfassung}
Für die Analyse der Gesichter in einem Video wurden zuerst die einzelnen Gesichter mittels MTCNN-Face Detection (\autoref{MTCNN}) in allen vorhanden Frames gesucht. Dieses Verfahren ist robust genug, dass es auch kleinste Gesichter im Bild erkennen kann und auch recht stabil bezüglich der Rotation. Somit ist es als Gesichtsdetektor geeignet um in einem Frame die Gesichter zu finden.\\
Anschließend wird jede Einzelperson unterschieden und alle gefundenen Bildbereiche der jeweiligen Person zugeordnet. Diese Bildbereiche werden nun auf eine Mindestgröße gebracht (\autoref{scale_Algos}), damit sie dem Trainingsdatensatz des nächsten Schrittes stärker ähneln. Dazu wurde die Auswirkung der verschieden Skalierungsverfahren auf die nachfolgende Analyse untersucht.\\
Nun werden die einzelnen Bildbereiche ausgewertet (\autoref{OpenFace}) und die Gesichtsorientierung kann bestimmt werden. Um die Bereiche zu simulieren in denen das Verfahren eingesetzt werden kann, wurden die Bild des Trainingsdatensatzes durch lineare Skalierung verkleinert.\\
Um die Detektion der Pupille zu verbessern wurde ElSe (\autoref{ElSe}) verwendet, mit dem Ziel, die Blickrichtung exakter zu ermitteln. Dazu wurde die Auswirkung der verschiedenen Farbbild nach Graubild Konvertierer (\autoref{Graubild}) untersucht, sowie die Veränderung des Radius der Maske.\\
Abschließend wurde getestet, wie zuverlässig das gesamte Verfahren auf Videos eingesetzt werden kann, um die Aufmerksamkeit zu ermitteln, siehe \autoref{VideoAnalyse}. Dazu wurde ein Versuch durchgeführt, bei dem die Probanden ein Ziel verfolgen sollten und ermittelt wie exakt das Ziel der Aufmerksamkeit bestimmt werden kann.\\
Durch den nachgewiesenen Wertebereich in dem eine Auswertung möglich ist, kann das gesamte Klassenzimmer mit nur einer Kamera erfasst werden. Bei Probanden deren Blickrichtung recht stark von der Kamera abweicht, ist das Erfassen zwar möglich, allerdings stärker fehlerbehaftet.