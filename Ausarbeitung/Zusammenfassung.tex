\section{Zusammenfassung}
Für die Analyse der Gesichter in einem Video, wurden zuerst die einzelnen Gesichtern mittels MTCNN-Face Detection (\autoref{MTCNN}) in allen vorhanden Frames gesucht.\\
Anschließend wird jede Einzelperson unterscheiden und alle gefunden Bildbereiche der jeweiligen Person zugeordnet. Diese Bildbereiche werden nun auf eine Mindestgröße gebracht (\autoref{scale_Algos}), damit sie den Trainingsdatensatz des nächsten Schrittes stärker ähneln. Dazu wurde die Auswirkung der verscheiden Skalierungsverfahren auf die nachfolgende Analyse untersucht.\\
Nun werden die einzelnen Bildbereiche Ausgewertet (\autoref{OpenFace}) und die Gesichtsorientierung kann bestimmt werden. Um die Bereiche zu simulieren in denen das Verfahren eingesetzt werden kann, wurde durch lineare Skalierung die Bild des Trainingsdatensatzes verkleinert um die verschiedenen Distanzen zu simulieren.\\
Um die Detektion der Pupille zu verbessern wurde ElSe (\autoref{ElSe}) verwendet, mit dem Ziel, die Blickrichtung exakter zu ermitteln. Dazu wurde die Auswirkung der verschiedenen Farbbild nach Graubild Konvertierer (\autoref{Graubild}) untersucht, sowie die Veränderung des Radius der Maske.\\
Abschließend wurde getestet, wie zuverlässig das gesamte Verfahren auf Videos eingesetzt werden kann, um die Aufmerksamkeit zu ermitteln, siehe \autoref{VideoAnalyse}. Dazu wurde ein Versuch durchgeführt, bei dem die Probanden ein Ziel verfolgen sollten und ermittelt wie exakt das ziel der Aufmerksamkeit bestimmt werden kann.\\
Durch den nachgewiesen Wertebereich in dem eine Auswertung möglich ist, kann das gesamte Klassenzimmer mit nur einer Kamera erfasst werden. Bei Probanden deren Blickrichtung recht stark von der Kamera abweicht, ist das Erfassen zwar möglich, allerdings starker Fehlerbehaftet.