\section{Zusammenfassung}

Für die Analyse der Gesichter in einem Video wurden zuerst die einzelnen Gesichter mittels MTCNN-Face Detection (\autoref{MTCNN}) in allen vorhanden Frames gesucht. Dieses Verfahren ist robust genug, dass auch kleinste Gesichter im Bild erkennen kann werden und auch recht stabil bezüglich der Rotation. Somit ist es als Gesichtsdetektor geeignet um in einem Frame die Gesichter zu finden.\\

Anschließend wird jede Einzelperson unterschieden und alle gefundenen Bildbereiche der jeweiligen Person zugeordnet. Diese Bildbereiche werden nun auf eine Mindestgröße gebracht (\autoref{scale_Algos}), damit sie dem Trainingsdatensatz des nächsten Schrittes stärker ähneln. Dazu wurde die Auswirkung der verschieden Skalierungsverfahren auf die nachfolgende Analyse untersucht und das lineare-Verfahren als das brauchbarste identifiziert.\\

Nun werden die einzelnen Bildbereiche ausgewertet (\autoref{OpenFace}) und die Gesichtsorientierung kann bestimmt werden. Um die Bereiche zu simulieren in denen das Verfahren eingesetzt werden kann, wurden die Bild des Trainingsdatensatzes durch lineare Skalierung verkleinert.\\

Um die Detektion der Pupille zu verbessern wurde ElSe (\autoref{ElSe}) verwendet, mit dem Ziel, die Blickrichtung exakter zu ermitteln. Um dieses Verfahren zu optimieren, wurde die Auswirkung der verschiedenen Farbbild nach Graubild Konvertierer (\autoref{Graubild}) untersucht, sowie die Veränderung des Radius der Maske und die Stabilität der Ergebnisse auf linear verkleinerten Eingabebilder. Die Messung hat ergeben, das eine Verbesserung durch ElSe vor allem bei sehr kleinen Bildern möglich ist, der Augendetektor von OpenFace allerdings auch sehr gute Ergebnisse liefert.\\

Um eine Übersicht über den Arbeitsbereich zu erhalten, wurden verschiedene Versuche durchgeführt um die maximalen Kopfrotationen und Distanzen zu bestimmen. Dabei konnte gezeigt werden, dass der Wertebereich in dem eine Auswertung möglich ist, ausreicht um das gesamte Klassenzimmer mit nur einer Kamera zu erfassen. Dabei zeigte sich, dass gerade die Bestimmung der Blickrichtung auf großer Distanz meist nicht möglich ist, da die Augenpartie viel zu klein für eine Berechnung ist. So bleibt meist nur die Gesichtsorientierung mit ihr natürlichen Ungenauigkeit.\\

Abschließend wurde getestet, wie zuverlässig das gesamte Verfahren auf Videos unter realen Bedingungen eingesetzt werden kann, um die Aufmerksamkeit zu ermitteln, siehe \autoref{VideoAnalyse}. Dazu wurde ein Versuch durchgeführt, bei dem die Probanden ein Ziel verfolgen sollten und ermittelt wie exakt das Ziel der Aufmerksamkeit bestimmt werden kann. Es zeigte sich schon in der Originalaufnahme, dass die Auswertung der Blickrichtung recht Fehler behaftet ist. Vor allem bei Probanden die dem Target vor allem mit den Auge gefolgt sind, zeigt sich die Problematik einer zuverlässigen Auswertung.\\

Da Bewegung erlaubt ist, passiert es immer wieder, dass Teile des Gesichtes verdeckt werden, durch Hände beim Melden, andere Schüler oder den Lehrer selbst, der vor der Kamera steht oder sich der Kopf zu weit wegdreht und das Tracking scheitert. Aber auch die Frisuren spielen eine Rolle, da dadurch diese einige Landmarks verdeckt werden können, wie z.B. die Augenbrauen, und das Gesicht nicht erkannt wird. Eine Problematik die schon in den Versuchen aufgetreten ist und mit großer Sicherheit auch in einem Großversuch auftreten wird.