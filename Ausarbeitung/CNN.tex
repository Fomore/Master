\section{Grundlagen}
Die Gesichtserkennung ist Teil der Bildverarbeitung und wird ständig weiterentwickelt. Darunter fallen neben der Detektion des Gesichtes auch seine Analyse wie Orientierung oder das erkennen von Mimiken und Übereinstimmungen. 
\subsection{Künstliches neuronales Netz}
Ein künstliches neuronales Netz besteht aus miteinander verknüpften künstlichen Neuronen. Jedes Neuron erhält Eingangswerte, diese werden individuelle Gewichtet, mittels einer Übertragungsfunktion zusammengefasst und durch eine Schwellenwertfunktion das Ergebnis bestimmt.\\
Um die Parameter der Neuronen zu bestimmen, werden sie zufällig initialisiert un dann so angepasst, dass sie zu einer gegebenen Eingabe das Gewünschte Ergebnis liefert und der Fehler über dem gesamten Trainingsdatensatzes minimal ist.
\subsubsection{To Do}
Quelle
\subsection{Convolutional Neural Network (CNN)}
CNN ist eine Weiterentwicklung der neuronalen Netzen und werden zur Klassifizierung verwendet, unter anderem im Bereich Bild- und Spracherkennung. Dies wird durch eine gewichtete Faltung der eingabe erreicht und sind  state of the art bei vielen Anwendungen.\\
Durch die Faltung werden die Information aus den umliegenden Punkten eines Bereiches zusammengefasst und komprimiert an die nächste Schicht weitergegeben, um in der untersten Schicht alle vorhanden Informationen zusammenzuführen. 
Der Faltungskern kann ja nach Anwendung beliebig gestaltet sein, so ist eine Glättung durch einen Gauß-Kernel oder Kantendetektion durch einen Kirsch-Operator möglich.\\
Ein CNN kann in zwei Bereiche aufgeteilt werden, der Feature Extraktion in welcher durch verschiedene Kernel und Komprimierung die Eingabeinformationen zur Klassifizierung, dem zweiten Bereich, aufbereitet.
Gelernt werden können die Kernel an sich und die jeweiligen Bewertungen.
\subsubsection{To Do}
Quelle\\
Bild
\subsection{Constrained Local Model (CLM)}
Dies ist ein Verfahren um mehrere Punkte eines Objektes zu lokalisieren. Dabei wird eine Wahrscheinlichkeitskarte für jeden einzelnen Punkt erstellt, wo dieser sich aufhalten kann auf Basis eines Trainingsdatensatzes. Nun wird versucht für das Bild, auf welchem gerechnet werden soll, für jeden Punkt den maximalen Wert zu erreichen zwischen passendem Farbverlauf und Wahrscheinlichkeit.\\
Dieser Art der Bestimmung von Punkten mit Positionsabhängigkeiten ist ziemlich zuverlässig und dennoch dynamisch genug um auch mit kleinen Veränderungen klar zu kommen.\\
Dies ist Wichtig, bei der Detektion von verschiedenen leicht verformbaren Objekten wie Gesichter und daher zuverlässiger als das Active Appearance Model (AAM).
\subsubsection{To Do}
Quelle\\
AAM\\
zur Detecton der Landmarks
\subsection{PDM \& GAVAM}
Mit Point Distribution Model (PDM) können verformbare Objekte recht gut modelliert werden. Dabei wird die durchschnittliche Form $\overline{X}$ bestimmt und eine Matrix $P$ von Eigenvektoren ermittelt, um die möglichen Deformierungen darzustellen.
\begin{align*}
X &= \overline{X}+P\cdot b
\end{align*}
Somit kann durch einen Skalierungsvektor $b$ alle möglichen Formen $X$ des Objektes dargestellt werden. Zur Vereinfachung reicht es, die signifikantesten Eigenvektoren in $P$ auf zu nehmen und dennoch $X$ ausreichend genau zu beschreiben.\\
Ist bekannt welche Art der Verformung durch den Eingenvektor dargestellt ist, z.B. eine bestimmte Orientierung, so kann anhand des Skallierungsvektors die Rotation des berechneten Objektes bestimmt werden, siehe Generalized Adaptive View-based Appearance Model (GAVAM). Eine Problematik bei dieser Art der Bestimmung der Rotation entsteht, wenn neben der Verschiebung der Landmarks durch die Rotation, auch eine Deformierung des Objektes stattgefunden hat und somit keine eindeutige Lösung gefunden werden kann. Dies ist eine Problematik wenn auf Gesichtern gerechnet wird, da immer eine Veränderung der Mundwinkel oder Augenlider vorhanden ist.\\
\cite{wiki_PDM}\cite{pdf_PDM}\cite{pdf_GAVAM}