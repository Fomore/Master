\section{Grundlagen}
Gesichtserkennung ist eine der fortschrittlichen Verfahren in der maschinellen Bildverarbeitung und wird ständig weiter entwickelt. Darunter fallen neben der Detektion des Gesichtes auch seine Analyse wie Orientierung oder das Erkennen von Mimik wie Lächeln bei Kameras und Übereinstimmungen.\\
Bei vielen Anwendungen ist der Stand der Technik oft ein Neuronales Netz beteiligt.
\subsection{Künstliches neuronales Netz}
Ein künstliches neuronales Netz besteht aus miteinander verknüpften künstlichen Neuronen. Jedes Neuron erhält Eingangswerte und besitzt einen Ausgabewert.\\
Um die Ausgabe zu bestimmen, werden die einzelne Eingangswerte des Neurons individuell Gewichtet, mittels einer Übertragungsfunktion zusammengefasst und durch eine Schwellenwertfunktion das Ergebnis bestimmt.\\
Um die Parameter (Gewichtung und Funktionen) des Neurons zu bestimmen, wird es zufällig initialisiert und dann so angepasst, dass es zu einer gegebenen Eingabe das Gewünschte Ergebnis liefert und der Fehler über dem gesamten Trainingsdatensatzes minimal ist.\\
Soll ein gesamtes Netz trainiert werden, so wird jedes einzelne Neuron zufällig Initialisiert und anschließend so angepasst das der Fehler auf einem Trainingsdatensatz minimal ist.\\
\cite{Maschin_Neuron}
\subsection{Convolutional Neural Network (CNN)}
CNN ist eine Weiterentwicklung der neuronalen Netze die vor allem im Bereich Klassifizierung eingesetzt werden, unter anderem bei der Bild- und Spracherkennung. Der unterschied liegt bei der Verwendung von gewichteten Faltungen der Eingabe erreicht. Die CNN definieren in vielen Anwendungsbereichen momentan der Stand der Technik.\\
Durch die Faltung werden die Information aus den umliegenden Punkten eines Bereiches zusammengefasst und komprimiert an die nächste Schicht weitergegeben, um in der untersten Schicht alle vorhanden Informationen zusammenzuführen. 
Der Faltungskern kann je nach Anwendung beliebig gestaltet sein, so ist eine Glättung durch einen Gauß-Kernel oder Kantendetektion durch einen Kirsch-Operator möglich.\\
Ein CNN kann in zwei Bereiche aufgeteilt werden, Feature Extraktion und Klassifizierung. Bei der Feature Extraktion werden verschiedene Kernel und Komprimierung auf den Eingabeinformationen angewendet um sie für den zweiten Teil aufzubereiten.
Gelernt werden können jeder einzelne Kernel für sich und die jeweiligen Bewertungen der einzelnen Kernel und Neuronen.\\
Quelle \& Bild
\subsection{Constrained Local Model (CLM)}
Dies ist ein Verfahren um mehrere Punkte eines Objektes zu lokalisieren. Dabei wird eine Wahrscheinlichkeitskarte für jeden einzelnen Punkt erstellt, wo dieser sich aufhalten kann, auf Basis eines Trainingsdatensatzes. Nun wird versucht für das Bild, auf welchem gerechnet werden soll, für jeden Punkt den maximalen Wert zu erreichen zwischen passendem Farbverlauf und seiner Wahrscheinlichkeit.\\
Dieser Art der Bestimmung von Punkten mit Positionsabhängigkeiten ist ziemlich zuverlässig und dennoch dynamisch genug um auch mit kleinen Veränderungen klar zu kommen.\\
Dies ist Wichtig, bei der Detektion von leicht verformbaren Objekten wie Gesichter und ist zuverlässiger als das Active Appearance Model (AAM).\\
Quelle \& Detecton der Landmarks
\subsection{Active Appearance Model (AAM)}
Dies ist ein Verfahren der Bildverarbeitung um Übereinstimmungen zu einem Modell zu finden. Dazu wird aus dem Trainingsdatensatz eine typische einheitliche Form des Objektes generiert mit seinen signifikanten Landmarks.\\
Soll nun zu eine Eingabebild die Übereinstimmung ermittelt werden, wird zuerst versucht es bestmöglich mittels Transformation in die typische einheitliche Form zu überführen. Sind dennoch Unterschiede vorhanden, liegt diese an der Erscheinung des Objektes.\\
\cite{wiki_AAM}
\subsection{Point Distribution Model (PDM) \& Generalized Adaptive View-based Appearance Model (GAVAM)}
Mit Point Distribution Model (PDM) können verformbare Objekte recht gut modelliert werden. Dabei wird die durchschnittliche Form $\overline{X}$ des Objekts anhand der Eingabe bestimmt und eine Matrix $P$ von Eigenvektoren ermittelt, um die möglichen Deformierungen darzustellen.
\begin{align*}
X &= \overline{X}+P\cdot b
\end{align*}
Somit kann durch einen Skalierungsvektor $b$ alle möglichen der Eingabeformen $X$ des Objektes aus dem Durchschnittsmodell dargestellt werden. Zur Vereinfachung reicht es, die signifikantesten Eigenvektoren in $P$ auf zu nehmen und dennoch $X$ ausreichend genau beschreiben zu können.\\
Ist bekannt welche Art der Verformung durch den Eingenvektor dargestellt ist, z.B. eine bestimmte Orientierung, so kann anhand des Skallierungsvektors die Rotation der Eingabe bestimmt werden, siehe Generalized Adaptive View-based Appearance Model (GAVAM).\\
Eine Problematik bei dieser Art der Bestimmung der Rotation entsteht, wenn neben der Verschiebung der Landmarks durch die Rotation, auch eine Deformierung des Objektes stattgefunden hat und somit keine eindeutige Lösung gefunden werden kann. Dies ist eine Problematik, wenn auf Gesichtern gerechnet wird, da immer eine Veränderung der Mundwinkel oder Augenlider vorhanden ist.\\
\cite{wiki_PDM}\cite{pdf_PDM}\cite{pdf_GAVAM}