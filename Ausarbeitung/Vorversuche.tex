\section{Versuch 1 - Arbeitsbereich der Verfahren}
Mit diesem Versuch soll der Zusammenhang zwischen Standort eines Probanden und Position des Blickziels (Targets) untersucht werden. Dazu wird eine Klassenzimmerumgebung simuliert, in der sowohl Standort als auch Blickziel relativ zur Kamera bekannt sind.\\
Als Messinstrument für die Versuche 1 und 2 wurde die Explorer 4K Actioncam verwendet, da sie eine hohe Auflösung bei ausreichend $FPS$ und eine $170^\circ$ Weitwinkel-Linse mit großer Schärfentiefe besitzt. Mit ihrer 2,7K Einstellung wird ein $2688 \times 1520$ Farbvideo mit $30FPS$ aufgezeichnet.\\
Allerdings ist die Bildqualität durch Pixelrauschen und Ähnliches deutlich schlechter als die Verkleinerung der Originalaufnahmen in den Datensätzen.
\subsection{Versuchsaufbau}
In einem Raum wurde die Kamera in $2,06m$ Höhe $31cm$ hinter den Targets so montiert, das der gesamte Raum im Fokus liegt. Als Targets wurden 9 Punkte auf einer Ebene markiert mit der Kamera im Zentrum. Die Anordnung der Targets ist in \autoref{img_aufbau_target_Test} dargestellt.\\
Als Position der Probanden wurde ein Rasterfeld mit $1m$ Kantenlänge im Raum eingezeichnet auf einer Fläche von $7 \times 11m$. Die Probanden stellten sich auf diesen Positionen auf um nacheinander alle Targets zu betrachten. 
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{PositionWinkel/Target}
	\caption{Aufbau der Targets im Vorversuch, alle Angaben gerundet in Zentimeter\\rote Punkte: Target, blauer Punkt: Kamera}
	\label{img_aufbau_target_Test}
\end{figure}
\subsection{Detektion mit MTCNN}
Um die Detektionswahrscheinlichkeit des MTCNN-Face Detektors zu testen wurden diese Videos analysiert.\\
Es zeigt sich, das auf allen Positionen die Probanden erfolgreich erkannt wurden und die Boxen das Gesicht recht gut beschreiben. Allerdings ist zu erkennen, das die Landmarks unzureichend genau sind. Sie sollten die Mundwinkel, Nasenspitze und beide Augen markieren, liegen aber schon bei recht großen Bildern weit daneben, siehe \autoref{img_bereich_MTCNN}
\begin{figure}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
		\includegraphics[width=1.1cm]{img_MTCNN/Img1-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img2-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img3-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img4-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img5-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img6-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img7-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img8-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img9-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img10-4_pupil1}&
		\includegraphics[width=1.1cm]{img_MTCNN/Img11-4_pupil1}\\
		\hline
		$1m$& $2m$& $3m$& $4m$& $5m$& $6m$& $7m$& $8m$& $9m$& $10m$& $11m$\\\hline
	\end{tabular}
	\caption{Dargestellt ist die Box und die 5 Landmarks von MTCNN-Face bei verschiedenen Distanzen des Probanden zur Actioncam}
	\label{img_bereich_MTCNN}
\end{figure}
\subsection{Auswertung}
Für die Analyse wurden aus dem Video jene Frames ausgewählt in denen ein Target fokussiert wurde und analysiert.\\
Für eine Analyse wurde zuerst die Einzelbildauswertung von OpenFace auf die Frames angewendet und jene Abbildungen der Kopfrotationen markiert, in denen erfolgreich ein Gesicht erkannt wurde. In \autoref{graph_Test_Bilder} ist der horizontale Wertebereich dargestellt in dem an der jeweiligen Position ein Gesicht erfolgreich erkannt wurde.\\
Im zweiten Teil wurden die selben Frames für die Messung verwendet, dieses mal allerdings wurde das gesamte Video analysiert. Der Winkelbereich in dem auf der horizontalen Achse an den entsprechenden Positionen ein Gesicht erkannt wurde, ist in \autoref{graph_Test_Video} dargestellt.\\
Das Fehlen von Ergebnissen in Spalte $-3m$ liegt an der unzureichenden Detektion. Als Ursache kann die Überbeleuchtung durch das einfallende Licht der Fenster angenommen werden.\\\\
Anschließend wurden die Verbesserungen getestet auf den Einzelbilder und dem gesamten Video.\\\\ 
Aufgrund von Pixelrauschen konnten die in \autoref{OpenFace_skal} theoretischen $14m$ Detektionsabstand, nicht erreicht werden, sondern nur $XXm$
\begin{figure}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline 
		$+5m$ & &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_-100_500.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_0_500.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_100_500.png} & \\ 
		\hline 
		$+4m$ & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_-200_400.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_-100_400.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_0_400.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_100_400.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_200_400.png} \\ 
		\hline 
		$+3m$ & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_-200_300.png} & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_-100_300.png} & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_0_300.png} & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_100_300.png} & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_200_300.png} \\ 
		\hline 
		$+2m$ & \includegraphics[width=1.4cm]{PositionWinkel/Winkel_-200_200.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_-100_200.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_0_200.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_100_200.png} & \\ 
		\hline 
		$+1m$ & &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_-100_100.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_0_100.png} &
		\includegraphics[width=1.4cm]{PositionWinkel/Winkel_100_100.png} & \\ 
		\hline 
		& $-2m$ & $-1m$ &Kamera& $+1m$ & $+2m$ \\ 
		\hline 
	\end{tabular}
	\caption{Dargestellt ist der horizontale Winkelbereich in dem mit der Image-Verarbeitung ein Gesicht erkannt wurde.}
	\label{graph_Test_Bilder}
\end{figure}
\begin{figure}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		$+5m$ &
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_200_500.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_100_500.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_0_500.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-100_500.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-200_500.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-300_500.png}\\ 
		\hline 
		$+4m$ &
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_200_400.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_100_400.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_0_400.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-100_400.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-200_400.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-300_400.png}\\ 
		\hline 
		$+3m$ &
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_200_300.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_100_300.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_0_300.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-100_300.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-200_300.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-300_300.png}\\ 
		\hline 
		$+2m$ & &
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_100_200.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_0_200.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-100_200.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-200_200.png} &\\ 
		\hline 
		$+1m$ & &
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_100_100.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_0_100.png}&
		\includegraphics[width=1.4cm]{PosWinkelVideo/Winkel_V_-100_100.png}& &\\ 
		\hline 
		& $-2m$ & $-1m$ &Kamera& $+1m$ & $+2m$ & $+3m$ \\ 
		\hline 
	\end{tabular}
	\caption{Dargestellt ist der horizontale Winkelbereich in dem mit der Video-Verarbeitung ein Gesicht erkannt wurde.}
	\label{graph_Test_Video}
\end{figure}
\subsection{Ergebnis}
Es zeigt sich, dass eine Auswertung auf einem Video deutlich zuverlässiger arbeitet als auf Einzelbildern, vor allem der größere Rotationsbereich ist von Vorteil.\\
Durch die Verwendung des Weitwinkelobjektivs, kann die gesamte Breite eines Klassenzimmers erfasst werden und der Winkelbereich für eine erfolgreiche Detektion ist breit genug um Schüler erfassen zu können, die selbst die vorderen Eckpunkte eines Klassenzimmers betrachten.\\
Bei der Distanz zur Kamera (Tiefe) besteht Handlungsbedarf, als Ziel wurde $8m$ angesetzt und das aktuelle Verfahren endet bei $5m$.\\
Eine signifikante Aussage bezüglich des vertikalen Winkel kann aus diesem Aufbau nicht getroffen werden, da die Neigungswinkel zu ähnlich bei stehenden Personen ausfallen (beides mal fast horizontal).
\section{Versuch 2 - Arbeitsbereich der Verfahren}
Da ein aufmerksamer Schüler durchaus auch auf den Tisch blicken kann, z.B. beim Schreiben, soll getestet werden wie weit die Analyse in solchen Situationen funktioniert.
\subsection{Versuchsaufbau}
Für diesen Versuch wurde die Kamera auf $1,88m$ Höhe und $3m$ vor dem vordersten Standort der Probanden aufgestellt.\\
Als Standorte wurde eine Markierung mit einem Meter Abstand zueinander auf einer Gerade bei $3m$ und $9m$ verwendet.\\
Als Target diente die Kamera, ein Punkt $78cm$ unterhalb der Kamera und einer $40cm$ über dem Boden und $50cm$ vor der Kamera. Alle anderen Targets befinden sich $1m$ vor den Standorten.\\
Diesmal war das Versuchsgelände draußen an einem bedecken Tag, wodurch eine helle schattenlose Szene entsteht.
\subsection{Auswertung}
ToDo
\subsection{Ergebnisse}
Es zeigt sich, das eine Videoanalyse auch bei starker Neigung nach unten möglich ist. Die Einzelbildauswertung liefert erneut deutlich schlechtere Ergebnisse als die Videoauswertung.\\
Dabei funktioniert das Traking nur, wenn die Versuchsperson zuerst in die Kamera geschaut hat, um es zu beginnen. Auch die stärkere gleichmäßige Beleuchtung ist hilfreich, da sie Probleme durch Gegenlicht und Schatten reduziert.
\section{Versuch 3 - Berechnung auf der Augenpartie}
Um einen Eindruck von ElSe mit hochauflösenden Aufnahmen zu erhalten, wurde mit einer Fotokamera (Sony ILCE-6000, Farbbild $6000\times 4000$ Pixel, Brennweite $16mm$) an den selben Positionen wie in Versuch 1 ein weiterer Datensatz von Einzelbildern erstellt, dabei wurden nur Aufnahmen mit der Kamera als Target gemacht. Von Interesse ist die Augenpartie und die Ergebnisse des OpenFace Eye-Detektor im Vergleich zu ElSe.\\
Dabei wurde ElSe in der Basiskonfiguration eingesetzt, dies bedeutet das Luminance-Verfahren, siehe \autoref{gray_Luminance} als Graukonvertierer und einem Radius der Maske von 12 Pixel.
\subsection{Auswertung}
Für die Analyse wurde zuerst mit OpenFace das Gesicht soweit analysiert um die Augenpartie als Eingabebild zu bestimmen, siehe \autoref{graph_Auge_Verbesserung} und ein Beispiel in \autoref{img_Versuch_Auge} oben. Auf diesem Eingabebild wird nun der ElSe-Algorithmus angewendet um die Ellipse zu bestimmen, dargestellt in grün. Im Vergleich sind die zusätzlichen 28 Landmarks der Augen von OpenFace auch in \autoref{img_Versuch_Auge} Mitte oben. Als Ergebnis wurde aus den berechneten Ellipsen von ElSe die Landmarks der Pupille und Iris abgeleitet und im selben Farbschema dargestellt.\\
Die einzelnen Augenpaare stammen von der selben Person, die sich bei der angegebenen Distanz frontal vor der Kamera befand. Es ist zu erkennen, das selbst bei einer hohen Auflösung die Augenpartie sehr klein ausfällt und nur schwierig auszuwerten ist.
\begin{figure}
	\centering
	\input{GraphAuge}
	\caption{Dargestellt sind der Ablauf, um die Landmarks des Auges zu verbessern}
	\label{graph_Auge_Verbesserung}
\end{figure}
\begin{figure}
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|} 
		\hline 
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_2}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_3}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_6}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_7}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_10}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_11}&	
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_14}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_15}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_17}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_19}&
		\includegraphics[width=0.07\linewidth]{img_Versuch_Auge/Auge_22}\\
		\hline 
		$1m$&$2m$&$3m$&$4m$&$5m$&$6m$&$7m$&$8m$&$9m$&$10m$&$11m$\\ 
		\hline 
	\end{tabular}
	\caption{Ergebnisse von OpenFace und ElSe bei verschiedenen Distanz.\\ Von Oben nach Unten: Augenparie, Ergebnis OpenFace, Ergebnis ElSe, ElSe Ergebnis als Landmarks}
	\label{img_Versuch_Auge}
\end{figure}
\subsection{Ergebnis}
Es zeigt sich, dass trotz einer hohen Bildauflösung der Informationsgehalt auf größere Distanzen deutlich abnimmt, wenn mit einer einzigen Kamera der gesamte Bereich einer Klasse erfasst werden soll. Außerdem ist auch gut zu erkennen, dass eine ausreichende Beleuchtung gebraucht wird, da die Augenregion sehr dunkel ausfällt.
\section{Ergebnis der Vorversuche}
Es zeigt sich, dass der Arbeitsbereich in Hinblick auf Rotationen ausreichend ist um alle üblichen Bewegungen eines Schülers zu erfassen. Auch die Fläche auf dem sich die Schüler verteilen können ist vielversprechend, nur die Distanz muss noch verbessert werden.\\
Auch MTCNN-Face ist als Detektor geeignet, er findet zuverlässige alle Gesichter im Frame, unabhängig ihrer Größe und Orientierung. Sogar jene die von OpenFace auch bei der Videoanalyse nicht verwendbar sind. Einzige Anmerkung ist die etwas ungenaue Box, dies kann aber mit einer einfachen Verschiebung der Boxränder korrigiert werden.