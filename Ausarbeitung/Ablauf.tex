\section{Ablauf der Implementierung}
Zur Bestimmung der Kopfposition und Orientierung wird ein mehrstufiges Verfahren eingesetzt. Am Anfang müssen alle Gesichter, die im aktuellen Frame vorhanden sind, detektiert werden. Dazu wird die MTCNN Face detection verwendet, da dieses Verfahren auch kleinste Gesichter erkennt, siehe \autoref{detection_Gesicht}\\
Für die weiteren Berechnungen muss bekannt sein, welchen Bereich von einem Gesicht im Frame eingenommen wird. Sind mehrere Gesichter in mehreren Frames des Videos abgebildet, so muss auch eine Identitätszuordnung vorgenommen werden, damit bekannt ist welches Gesicht in Bild 1 welchem in Bild 2 entspricht.\\
Damit OpenFace zuverlässig arbeiten kann, werden alle zu kleinen Bildbereiche hochskaliert, um die Gesichter auf eine Mindestgröße zu bringen, siehe \autoref{skalierung}\\
Diese Bildbereiche werden nun mit OpenFace weiterverarbeitet, um die Position der Landmarkes zu bestimmen. Durch die vorige Zuordnung der Gesichert kann OpenFace gezielt auf dieser Person arbeiten und sich entsprechend darauf einstellen, um so bessere Ergebnisse zu erzielen. Außerdem könne alle gefundenen Personen gleichzeitig (parallel) ausgewertet werden, siehe \autoref{bestimmung_Landmarks}\\
Um die Position der Pupille noch exakter zu ermitteln kann ElSe verwendet werden, nur durch eine exakte Bestimmung der Pupillenposition ist auch eine genaue Blickrichtungsbestimmung möglich. Allerdings muss das Ergebnis von ElSe auf Plausibilität geprüft werden, um grobe Fehler zu vermeiden, siehe \autoref{verbesserung_ElSe}.\\
Nun wird auf Basis der Landmarks und der Kameraparameter die Position und Orientierung des jeweiligen Gesichtes bestimmt. Diese kann dann von weiteren Anwendungen verwendet werden. \autoref{bestimmung_Pos}