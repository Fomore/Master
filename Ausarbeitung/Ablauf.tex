\section{Ablauf der Implementierung}
Zur Bestimmung der Kopfposition und Orientierung wird ein mehrstufiges Verfahren eingesetzt. Am Anfang müssen alle Gesichter, die im aktuellen Frame vorhanden sind, detektiert werden. Dazu wird die MTCNN Face detection verwendet, da dieses Verfahren auch kleinste Gesichter erkennen kann. \ref{detection_Gesicht}\\
Für die weiteren Berechnungen muss bekannt sein welchen Bereich das Gesicht in Frame einnimmt und um welches es sich handelt. Der Bereich wird vom MTCNN als Box geliefert, als Personenzuordnung wird ein Matsching zum vorigen Frame verwendet.\\
Damit auch eine Berechnung auf den kleineren Gesichtern stattfinden kann, werden alle zu kleinen Bildbereiche hochskalliert. Dabei muss wegen Ungenauigkeiten die gefundene Box etwas vergrößert und sollte dann auf eine Mindestgröße gebracht werden. \ref{skalierung}\\
Diese Bildbereiche werden nun mit OpenFace weiterverarbeitet, um die Position der Landmarkes im Bild zu bestimmen. Durch die Berechnung auf der selben Person kann das CNN sich auf jeden einzeln einstellen, um so bessere Ergebnisse zu erreichen. Außerdem könne alle gefundenen Personen gleichzeitig (parallel) ausgewertet werden. \ref{bestimmung_Landmarks}\\
Bei großen Gesichtern wird nun ElSe auf den Augenbereich angewendet, um die Position der Pupille noch exakter zu ermitteln, damit die Blickrichtung genauer wird. Dazu muss allerdings die Differenz zwischen ElSe-Ergebnis und OpenFace-Ergebnis betrachtet werden um Fehler zu erkennen.\ref{verbesserung_ElSe}\\
Nun wird auf Basis der Landmarks und der Kameraparameter die Position und Orientierung des jeweiligen Gesichtes bestimmt und können für weitere Anwendungen verwendet werden. \ref{bestimmung_Pos}