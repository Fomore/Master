\section{Gesichtsanalyse mit OpenFace}
\label{OpenFace}
OpenFace ist ein Open-Source Echtzeitverfahren auf Basis von CLNF für die Bestimmung und Analyse von Gesichtsmerkmalen in Graubildern und Videos. Dieses Verfahren wurde gewählt, da es zum aktuellen Stand der Technik gehört und viele Probleme der Gesichtsanalyse löst. Dazu gehört neben der zuverlässigen Bestimmung der Landmarks, auch die Fähigkeit zur bestimmung der 3D-Position, ermittlung der Blickrichtung und die Fähigkeit zu lernen. Dabei stehen in der aktuellen Anwendung neben dem Farbbild nur die Kameraparameter zur Verfügung und keinerlei Zusätze wie ein Tiefenbild (kann mitverwendet werden wenn es vorhanden ist) oder Infrarotbeleuchtung der Szene.\\
OpenFace kann 68 Landmarks ermitteln, die das Gesicht beschreiben, und mit deren Hilfe Position, Blickrichtung und Gesichtsmerkmale bestimmen. Sollte ein Video als Quelle fungieren, kann OpenFace auch lernen, wodurch eine zuverlässigere Verarbeitung erzielt werden kann.\\
Als Ergebnis ist die Kopfposition (Translation und Orientierung) sowie Blickrichtung von Interesse, da mit ihnen zurückrechnet werden kann wohin die Person schaut.\\
Der Rechenaufwand zur Verarbeitung des Eingabebildes ist so ausgelegt, das ein Webcam-Video in Echtzeit ausgewertet werden kann, dies ist im aktuellen Fall nicht notwendig, da es sich um eine nachträgliche Auswertung handelt, bei der es vor allem um Genauigkeit geht.
\subsection{Gesichts-Landmarks: Detektion und Verfolgung}
Für die Bestimmung und Tracking der Landmarks wird ein Conditional Local Neural Fields (CLNF) eingesetzt, dabei handelt es sich im Grunde um ein Constrained Local Model (CLM). Es wird das Point Distribution Model (PDM) zum Erfassen der Anordnung der Landmarks sowie ein verbessertes Patch Experts zum Erfassen der Variante der einzelnen Landmarks verwendet.\\
Zu Beginn werden verschiedene initiale Hypothesen aus der dlib-Bibliothek verwendet und die Passende zur Eingabe ausgewählt. Bei den unterschiedlichen initial Hypothesen handelt es sich um die Darstellung verschiedener Gesichtsorientierungen auf denen unterschiedliche Netze trainiert wurden. Diese Herangehensweise ist langsam, aber auch exakter als eine einfache Hypothese. Wird ein Tracking, das Verfolgen der Landmarks über mehrere Frames, durchgeführt wird als initiale Hypothese das Ergebnis aus der letzten Eingabe verwendet. Sollte das Tracking scheitern, wird das CNN reseted um Neu zu beginnen mit den ursprünglichen Hypothesen.\\
Auf diese Weise werden 68 Gesichts-Landmarks und weitere 28 pro Auge bestimmt.\\
Für eine zuverlässige Detektion der Gesichter, sollten diese laut Paper \cite{OpenFace} eine Größe von 100 Pixeln aufweisen.
\subsection{Veröffentlichte Genauigkeit der Kopforientierung}
Um die Qualität der Berechnung auf dem Kopf zu bewerten wurde im Paper \cite{OpenFace} der \glqq Biwi Kinect head pose\grqq \cite{BIWI_database}, \glqq ICT-3DHP\grqq \cite{ICT_database} und \glqq BU Datensatz\grqq \cite{BU_database} ausgewertet. Dabei handelt es sich um Portrait-Fotos von Probanden, deren Körper in Richtung Kamera ausgerichtet sind und ihren Kopf in eine beliebige Richtung drehen. Für die Genauigkeit der bestimmten Kopfposition haben sich folgende Werte in \autoref{OpenFace_Error} ergeben, Angraben in Grad.\\
Für die Qualität zur Bestimmung der Blickrichtung wurde der Augendatensatz \glqq Appearancebased gaze estimation in the wild\grqq \cite{database_Eye_old} zur Bestimmung der Blickrichtung verwendet und es ergab sich ein durchschnittlichen Fehler von $9,96$ Grad.
\begin{figure}[h]
	\centering
	\begin{tabular}{|l|c|c|c||c|c|}
		\hline
		&Yaw&Pitch&Roll&Mean&Median\\\hline
		BIWI&7.9&5.6&4.5&6.0&2.6\\\hline
		BU dataset&2.8&3.3&2.3&2.8&2.0\\\hline
		ICT-3DHP&3.6&3.6&3.6&3.6&-\\\hline
	\end{tabular}
	\caption{Veröffentlichte Abweichung von OpenFace auf verschiedenen Datensätze, bestimmt von \cite{OpenFace}}
	\label{OpenFace_Error}
\end{figure}